<!DOCTYPE html>
<html>
   <head>
      
   <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
   
   <style type="text/css" media="all">

	body{background: #466368;
		background: -webkit-linear-gradient(#999999, #990000);
		background:    -moz-linear-gradient(#999999, #990000);
		background:         linear-gradient(#999999, #990000);}
	img{}
	h2{ color:#00FFFF; font-size:30px; text-align:center;}
	h3{ color:white; font-size:20px; text-align:left;}
	ol{ color:white; font-family:Times New Roman; font-style:normal; font-size:20pt; }
	table{ color:white; font-family:Arial; font-style:normal; font-size:13pt }
	
	
	p{ color:white; text-align:left; margin: 10px 100px;}
	
	a{color:white;}
	
	h3 {
		margin: 30px 100px;
		color: Orange;
	}
	
	</style>
		<link rel="stylesheet" type="text/css" href="PPS_WebsiteStyleSheet.css" />
	<div class="rightLinks">
            <div class="linkTitle">Links:</div>
    			<div class="links" text-align=left; >
				<a href="Parallel Prog. Site.html">Home Page</a><br />
                <a href="Introduction.html">Chapter 1</a><br />
                <a href="chapter2.html">Chapter 2</a><br />
                <a href="chapter3.html">Chapter 3</a><br />
                <a href="chapter4.html">Chapter 4</a><br />
                <a href="chapter5.html">Chapter 5</a><br />
				<a href="chapter6.html">Chapter 6</a><br />
                <a href="chapter7.html">Chapter 7</a><br />
                <a href="chapter8.html">Chapter 8</a><br />
                <a href="chapter9.html">Chapter 9</a><br />
                <a href="chapter10.html">Chapter 10</a><br />
				<a href="chapter11.html">Chapter 11</a><br />
                <a href="chapter12.html">Chapter 12</a><br />
                <a href="chapter13.html">Overview</a><br />
				</div>
        </div>
      <title>    Chapter 11       </title>
   </head>
   <body><meta name = "keywords" content = "computer, science, intro, 100, CSC, HTML">
   			<div id="image" style="display:inline;">
			<center><img style="height:147px; width:486px" src="StMartinlogoTP.png"/>
			</div>
			
			<h2>  Chapter 11 - MPI Collective Communication </h2></font>
			<center><p>
<h3>MPI_Bcast</h3>
<center><img  src="23.png"/>
 
<p>If comm is an intracommunicator, MPI_BCAST broadcasts a message from the process with rank root to all processes of the group, itself included. It is called by all members of the group using the same arguments for comm and root. On return, the content of root’s buﬀer is copied to all other processes. 

<p>General, derived datatypes are allowed for datatype. The type signature of count, datatype on any process must be equal to the type signature of count, datatype at the root. This implies that the amount of data sent must be equal to the amount received, pairwise between each process and the root. MPI_BCAST and all other data-movement collective routines make this restriction. Distinct type maps between sender and receiver are still allowed.


<p><h3>MPI_Reduce</h3>
<p>The reduction operation can be either one of a predeﬁned list of operations, or a user-deﬁned operation. The global reduction functions come in several ﬂavors: a reduce that returns the result of the reduction to one member of a group, an all-reduce that returns this result to all members of a group, and two scan (parallel preﬁx) operations. In addition, a reduce-scatter operation combines the functionality of a reduce and of a scatter operation.
 
<center><img  src="24.png"/>

<p><h3>MPI_Allreduce</h3>
<p>MPI includes a variant of the reduce operations where the result is returned to all processes in a group. MPI requires that all processes from the same group participating in these operations receive identical results.
 
<center><img  src="25.png"/>

<p><h3>MPI_Barrier</h3>
<p>If comm is an intracommunicator, MPI_BARRIER blocks the caller until all group members have called it. The call returns at any process only after all group members have entered the call. If comm is an intercommunicator, MPI_BARRIER involves two groups. The call returns at processes in one group (group A) of the intercommunicator only after all members of the other group (group B) have entered the call (and vice versa). A process may return from the call before all processes in its own group have entered the call.
 
<center><img  src="26.png"/>

<p><h3>MPI_Scatter</h3>
<p>MPI_SCATTER is the inverse operation to MPI_GATHER. If comm is an intracommunicator, the outcome is as if the root executed n send operations, and each process executed a receive.
 
<center><img  src="27.png"/>
<p><b>More information on the subject can be found here:</b>
<p>(https://www.mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf) 

			</center></p>

			
			<p><a href = "https://moodle.stmartin.edu/">Link to Course Moodle Page</a>


   </body>
</html>